// Isilon â€“ Normalize DQL capacity rows into TB, %, and status
// Input is expected to be the raw DQL array, e.g.:
// [
//   {
//     clusterName: "Isilon-Prod-01",
//     used_bytes: 277.234234234,
//     total_bytes: 47.23423423,
//     used_hdd_bytes: 34534534534534,
//     total_hdd_bytes: 34534534534534534,
//     used_sdd_bytes: 345345345345345,
//     total_sdd_bytes: 345345345345
//   },
//   ...
// ]
//
// In the Workflow, map this JS step's input to that array directly:
//   input = {{ steps.isilon_capacity_dql.output }}   (or the correct path)
//
// Output:
//   {
//     clusters: [ ...normalized objects... ]
//   }

export default async function (input) {
  // If input is the array itself, use it; if it's wrapped, you can later switch to input.rows or input.records.
  const rows = Array.isArray(input) ? input : (input.rows || input.records || []);

  const BYTES_PER_TB = 1_000_000_000_000;

  function safeNum(x) {
    const n = Number(x);
    return Number.isFinite(n) ? n : 0;
  }

  // For HDD/SSD fields, we know theyâ€™re bytes (huge values), so always convert.
  function bytesToTB(value) {
    const n = safeNum(value);
    return n / BYTES_PER_TB;
  }

  function badge(p) {
    const n = Number(p);
    if (!Number.isFinite(n)) return "âšª N/A";
    if (n < 70) return "ðŸŸ¢ Healthy";
    if (n < 85) return "ðŸŸ¡ Warning";
    return "ðŸ”´ Critical";
  }

  const clusters = rows
    .map((row) => {
      const clusterName = row.clusterName ?? row.name ?? "Unknown";

      // OVERALL
      // Your example clearly looks like these are already TB-like values:
      //   used_bytes: 277.234...
      //   total_bytes: 47.234...
      // So we treat them as TB directly, not bytes.
      const usedTB  = safeNum(row.used_bytes);
      const totalTB = safeNum(row.total_bytes);

      const usedPct = totalTB > 0 ? (usedTB / totalTB) * 100 : 0;

      // HDD / SSD (these look like real bytes, huge values)
      const usedHddTB  = bytesToTB(row.used_hdd_bytes);
      const totalHddTB = bytesToTB(row.total_hdd_bytes);
      const usedSddTB  = bytesToTB(row.used_sdd_bytes);
      const totalSddTB = bytesToTB(row.total_sdd_bytes);

      const usedHddPct = totalHddTB > 0 ? (usedHddTB / totalHddTB) * 100 : 0;
      const usedSddPct = totalSddTB > 0 ? (usedSddTB / totalSddTB) * 100 : 0;

      return {
        clusterName,

        // Overall (TB and %)
        usedTB:  usedTB.toFixed(1),
        totalTB: totalTB.toFixed(1),
        usedPct: usedPct.toFixed(1),

        // HDD breakdown
        usedHddTB:  usedHddTB.toFixed(1),
        totalHddTB: totalHddTB.toFixed(1),
        usedHddPct: usedHddPct.toFixed(1),

        // SSD breakdown
        usedSddTB:  usedSddTB.toFixed(1),
        totalSddTB: totalSddTB.toFixed(1),
        usedSddPct: usedSddPct.toFixed(1),

        // Traffic light status based on overall usage
        status: badge(usedPct)
      };
    })
    .sort((a, b) => a.clusterName.localeCompare(b.clusterName));

  // This is what you'll see in the JS step output
  return {
    rowCount: rows.length,
    clusters
  };
}
