import { credentialVaultClient } from "@dynatrace-sdk/client-classic-environment-v2";
import { result } from "@dynatrace-sdk/automation-utils";

/**
 * cohesity_backup_failures_p3
 * - GET-only
 * - HEAVY runs (includeObjectDetails=true)
 * - Partial rerun logic (same as PowerShell):
 *   latest failure per object with NO later object-level success (within last N runs), per RunType
 *
 * IMPORTANT FIX vs earlier JS:
 * - Helios sometimes returns singletons (object) instead of arrays for:
 *     run.objects, localBackupInfo, localSnapshotInfo.failedAttempts
 *   PowerShell @() handles that; JS must normalize. This script does.
 */
export default async function () {
  const PART2 = "cohesity_backup_failures_p2";
  const p2 = await result(PART2);
  if (!p2?.baseUrl || !Array.isArray(p2.pgIndex)) {
    throw new Error(`Part 3: missing Part 2 output. Check step name: ${PART2}`);
  }

  const baseUrl = p2.baseUrl;
  const numRuns = Number(p2.numRuns ?? 10);
  const pgIndex = p2.pgIndex;

  // Vault auth (required)
  const vaultId = "credentials_vault-312312";
  const vaultCred = await credentialVaultClient.getCredentialsDetails({ id: vaultId });
  const apiKey = (vaultCred?.token || vaultCred?.password || "").trim();
  if (!apiKey) throw new Error("No Helios API key available (empty token/password).");

  const commonHeaders = { accept: "application/json", apiKey };

  // -----------------------------
  // helpers
  // -----------------------------
  const sleep = (ms) => new Promise((r) => setTimeout(r, ms));

  function toArray(v) {
    if (v == null) return [];
    return Array.isArray(v) ? v : [v];
  }

  function getInfo(run) {
    const lb = run?.localBackupInfo;
    if (!lb) return null;
    return Array.isArray(lb) ? (lb[0] ?? null) : lb;
  }

  async function getJsonWithRetry(url, headers, retries = 2) {
    for (let i = 0; i <= retries; i++) {
      const resp = await fetch(url, { method: "GET", headers });
      if (resp.ok) return resp.json();

      const st = resp.status;
      if ((st === 429 || st >= 500) && i < retries) {
        await sleep(700 * (i + 1));
        continue;
      }

      let txt = "";
      try { txt = await resp.text(); } catch (_) {}
      throw new Error(`GET ${url} -> HTTP ${st} ${txt}`);
    }
    return null;
  }

  function cleanMsg(s) {
    if (!s) return "";
    return String(s).replace(/[\r\n]+/g, " ").replace(/\|/g, " ").replace(/"/g, "'").trim();
  }

  function fmtETFromUsecs(usecs) {
    if (!usecs) return "";
    const ms = Math.floor(Number(usecs) / 1000);
    const dt = new Date(ms);
    try {
      return new Intl.DateTimeFormat("en-US", {
        timeZone: "America/New_York",
        year: "numeric",
        month: "2-digit",
        day: "2-digit",
        hour: "2-digit",
        minute: "2-digit",
        hour12: false,
      }).format(dt);
    } catch {
      return dt.toISOString();
    }
  }

  function getObjKey(ob) {
    const o = ob?.object;
    if (!o) return "";
    if (o.id) return String(o.id);
    const sid = o.sourceId ? String(o.sourceId) : "";
    return `${o.environment || ""}|${o.objectType || ""}|${o.name || ""}|${sid}`;
  }

  function failedAttemptsArr(ob) {
    return toArray(ob?.localSnapshotInfo?.failedAttempts);
  }

  function hasFailedAttempts(ob) {
    return failedAttemptsArr(ob).length > 0;
  }

  function isObjectSuccess(ob) {
    // PowerShell logic: object present in run + no failedAttempts => success clearing older failures
    return !!ob?.localSnapshotInfo && !hasFailedAttempts(ob);
  }

  function combineFailedAttempts(attempts) {
    const arr = toArray(attempts);
    const msgs = arr.map((a) => cleanMsg(a?.message)).filter(Boolean);
    return msgs.join(" | ");
  }

  async function mapLimit(items, limit, fn) {
    const out = [];
    let i = 0;
    const workers = Array.from({ length: Math.min(limit, items.length) }, async () => {
      while (true) {
        const idx = i++;
        if (idx >= items.length) break;
        const vals = await fn(items[idx], idx);
        if (Array.isArray(vals) && vals.length) out.push(...vals);
      }
    });
    await Promise.all(workers);
    return out;
  }

  // heavy calls: keep conservative
  const CONCURRENCY = 3;
  const pgErrors = [];

  async function processPg(pg) {
    const headers = { ...commonHeaders, Accept: "application/json", accessClusterId: String(pg.clusterId) };

    const url =
      `${baseUrl}/v2/data-protect/protection-groups/${encodeURIComponent(String(pg.pgId))}` +
      `/runs?numRuns=${numRuns}&excludeNonRestorableRuns=false&includeObjectDetails=true`;

    let jsonRuns;
    try {
      jsonRuns = await getJsonWithRetry(url, headers, 2);
    } catch (e) {
      pgErrors.push({ cluster: pg.clusterName, pg: pg.pgName, error: String(e?.message || e) });
      return [];
    }

    const runs = toArray(jsonRuns?.runs);
    if (!runs.length) return [];

    const runTypes = Array.from(
      new Set(
        runs
          .map((r) => getInfo(r)?.runType)
          .filter(Boolean)
          .map((x) => String(x))
      )
    );

    const failuresOut = [];

    for (const rType of runTypes) {
      const runsForType = runs
        .filter((r) => String(getInfo(r)?.runType || "") === rType)
        .sort((a, b) => Number(getInfo(b)?.endTimeUsecs || 0) - Number(getInfo(a)?.endTimeUsecs || 0));
      if (!runsForType.length) continue;

      // best-effort id->name mapping (PowerShell does this across runs)
      const idToName = new Map();
      for (const rr of runsForType) {
        for (const ob of toArray(rr?.objects)) {
          const o = ob?.object;
          if (o?.id && o?.name && !idToName.has(String(o.id))) idToName.set(String(o.id), String(o.name));
        }
      }

      const cleared = new Set();         // object keys cleared by newer success
      const latestFailByKey = new Map(); // first failure encountered newest->oldest

      for (const run of runsForType) {
        const info = getInfo(run) || {};
        const endTimeET = fmtETFromUsecs(info?.endTimeUsecs);

        const objsAll = toArray(run?.objects).filter((x) => x?.object && x?.localSnapshotInfo);

        // run-level fallback
        if (!objsAll.length) {
          if (String(info.status || "") === "Failed") {
            const rk = `RUNLEVEL|${pg.pgId}|${rType}`;
            if (!latestFailByKey.has(rk)) {
              const msg = Array.isArray(info.messages) ? info.messages.join(" | ") : info.messages;
              latestFailByKey.set(rk, {
                Environment: pg.pgEnv,
                Cluster: pg.clusterName,
                ProtectionGroup: pg.pgName,
                Host: "",
                ObjectType: "RunLevel",
                ObjectName: "(Run-level)",
                RunType: rType,
                EndTimeET: endTimeET,
                FailedMessage: cleanMsg(msg),
              });
            }
          }
          continue;
        }

        // 1) mark successes (newer clears older failures)
        for (const ob of objsAll) {
          if (isObjectSuccess(ob)) {
            const k = getObjKey(ob);
            if (k) cleared.add(k);
          }
        }

        // 2) capture latest uncleared failures per object
        for (const ob of objsAll) {
          const k = getObjKey(ob);
          if (!k) continue;
          if (cleared.has(k)) continue;
          if (latestFailByKey.has(k)) continue;
          if (!hasFailedAttempts(ob)) continue;

          const msg = combineFailedAttempts(failedAttemptsArr(ob));
          if (!msg) continue;

          const o = ob.object || {};
          let hostName = "";
          if (o.sourceId && idToName.has(String(o.sourceId))) hostName = idToName.get(String(o.sourceId));

          latestFailByKey.set(k, {
            Environment: o.environment ? String(o.environment) : pg.pgEnv,
            Cluster: pg.clusterName,
            ProtectionGroup: pg.pgName,
            Host: hostName,
            ObjectType: o.objectType ? String(o.objectType) : "UnknownType",
            ObjectName: o.name ? String(o.name) : "",
            RunType: rType,
            EndTimeET: endTimeET,
            FailedMessage: msg,
          });
        }
      }

      for (const v of latestFailByKey.values()) failuresOut.push(v);
    }

    return failuresOut;
  }

  const failures = await mapLimit(pgIndex, CONCURRENCY, processPg);

  return {
    authMode: "vault",
    baseUrl,
    numRuns,
    pgIndexCount: pgIndex.length,
    pgErrors,
    pgErrorsCount: pgErrors.length,
    failures,
    failuresCount: failures.length,
  };
}
