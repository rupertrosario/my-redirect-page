import { credentialVaultClient } from "@dynatrace-sdk/client-classic-environment-v2";
import { result } from "@dynatrace-sdk/automation-utils";

/**
 * cohesity_backup_failures   ✅ keep this exact name so everything below snow_search stays the same
 * READ-ONLY (GET-only)
 *
 * - Vault auth inside Part 3  ✅
 * - Reads Part 2 output via result("cohesity_backup_failures_p2")
 * - HEAVY runs (includeObjectDetails=true) only for PG worklist
 * - Failure rule: latest failure per object with NO later success within last numRuns
 *
 * Returns (same shape pattern you showed) + pgWorkItemsCount (debug-safe extra)
 */
export default async function () {
  const PART2_TASK = "cohesity_backup_failures_p2";

  // TEMP CHECK (embedded, but DOES NOT break downstream because we don't early-return)
  const p2 = await result(PART2_TASK);
  const pgWorkItemsCount = (p2?.pgWorkItems || []).length;

  if (!p2 || !Array.isArray(p2.pgWorkItems)) {
    throw new Error(`Part 3: missing Part 2 output. Check task name: ${PART2_TASK}`);
  }

  const baseUrl = p2.baseUrl || "https://helios.cohesity.com";
  const numRuns = Number(p2.numRuns ?? 5);
  const pgWorkItems = p2.pgWorkItems;

  // ==============================
  // AUTH (vault id)  ✅
  // ==============================
  const vaultId = "credentials_vault-312312";
  const d2 = await credentialVaultClient.getCredentialsDetails({ id: vaultId });
  const apiKey = (d2?.token || d2?.password || "").trim();
  if (!apiKey) throw new Error("No Helios API key available (empty token/password).");

  const commonHeaders = { accept: "application/json", apiKey };

  async function getJson(url, headers) {
    const resp = await fetch(url, { method: "GET", headers });
    if (!resp.ok) {
      let txt = "";
      try { txt = await resp.text(); } catch (_) {}
      throw new Error(`GET ${url} -> HTTP ${resp.status} ${txt}`);
    }
    return resp.json();
  }

  function cleanMsg(s) {
    if (!s) return "";
    return String(s)
      .replace(/[\r\n]+/g, " ")
      .replace(/\|/g, " ")
      .replace(/"/g, "'")
      .trim();
  }

  function fmtETFromUsecs(usecs) {
    if (!usecs) return "";
    const ms = Math.floor(Number(usecs) / 1000);
    const d = new Date(ms);
    try {
      return new Intl.DateTimeFormat("en-US", {
        timeZone: "America/New_York",
        year: "numeric",
        month: "2-digit",
        day: "2-digit",
        hour: "2-digit",
        minute: "2-digit",
        hour12: false,
      }).format(d);
    } catch {
      return d.toISOString();
    }
  }

  function getObjKey(ob) {
    const o = ob?.object;
    if (!o) return "";
    if (o.id) return String(o.id);
    const sid = o.sourceId ? String(o.sourceId) : "";
    return `${o.environment || ""}|${o.objectType || ""}|${o.name || ""}|${sid}`;
  }

  function hasFailedAttempts(ob) {
    const fa = ob?.localSnapshotInfo?.failedAttempts;
    return Array.isArray(fa) && fa.length > 0;
  }

  function isSuccessForClear(ob) {
    return ob?.localSnapshotInfo && !hasFailedAttempts(ob);
  }

  function combineFailedAttempts(attempts) {
    if (!Array.isArray(attempts) || attempts.length === 0) return "";
    const msgs = attempts.map((a) => cleanMsg(a?.message)).filter(Boolean);
    return msgs.join(" | ");
  }

  function etDateYYYYMMDD() {
    const now = new Date();
    const parts = new Intl.DateTimeFormat("en-CA", {
      timeZone: "America/New_York",
      year: "numeric",
      month: "2-digit",
      day: "2-digit",
    })
      .formatToParts(now)
      .reduce((a, p) => ((a[p.type] = p.value), a), {});
    return `${parts.year}-${parts.month}-${parts.day}`;
  }

  async function collectAllFailures() {
    const out = [];

    for (const wi of pgWorkItems) {
      const headers = {
        ...commonHeaders,
        Accept: "application/json",
        accessClusterId: String(wi.clusterId),
      };

      let runsHeavyJson;
      try {
        runsHeavyJson = await getJson(
          `${baseUrl}/v2/data-protect/protection-groups/${encodeURIComponent(
            String(wi.pgId)
          )}/runs?numRuns=${numRuns}&excludeNonRestorableRuns=false&includeObjectDetails=true`,
          headers
        );
      } catch (_) {
        continue;
      }

      const runs = Array.isArray(runsHeavyJson?.runs) ? runsHeavyJson.runs : [];
      if (!runs.length) continue;

      const runTypes = Array.from(
        new Set(
          runs
            .map((r) => r?.localBackupInfo?.[0]?.runType)
            .filter(Boolean)
            .map(String)
        )
      );

      for (const rType of runTypes) {
        const runsForType = runs
          .filter((r) => String(r?.localBackupInfo?.[0]?.runType || "") === rType)
          .sort(
            (a, b) =>
              Number(b?.localBackupInfo?.[0]?.endTimeUsecs || 0) -
              Number(a?.localBackupInfo?.[0]?.endTimeUsecs || 0)
          );

        if (!runsForType.length) continue;

        // best-effort host map from newest run only (faster)
        const idToName = new Map();
        const newestObjs = Array.isArray(runsForType[0]?.objects) ? runsForType[0].objects : [];
        for (const ob of newestObjs) {
          const o = ob?.object;
          if (o?.id && o?.name && !idToName.has(String(o.id))) {
            idToName.set(String(o.id), String(o.name));
          }
        }

        const cleared = new Set();
        const latestFailByKey = new Map();

        for (const run of runsForType) {
          const info = run?.localBackupInfo?.[0] || {};
          const endTimeET = fmtETFromUsecs(info.endTimeUsecs);

          const objsAll = (Array.isArray(run?.objects) ? run.objects : []).filter(
            (x) => x?.object && x?.localSnapshotInfo
          );

          // run-level fallback (rare)
          if (!objsAll.length) {
            if (info.status === "Failed") {
              const rk = `RUNLEVEL|${wi.pgId}|${rType}`;
              if (!latestFailByKey.has(rk)) {
                const msg = Array.isArray(info.messages) ? info.messages.join(" | ") : info.messages;
                latestFailByKey.set(rk, {
                  Environment: wi.pgEnv,
                  Cluster: wi.clusterName,
                  ProtectionGroup: wi.pgName,
                  Host: "",
                  ObjectType: "RunLevel",
                  ObjectName: "(Run-level)",
                  RunType: rType,
                  EndTimeET: endTimeET,
                  FailedMessage: cleanMsg(msg),
                });
              }
            }
            continue;
          }

          // Pass 1: mark successes (newer clears older)
          for (const ob of objsAll) {
            if (isSuccessForClear(ob)) {
              const k = getObjKey(ob);
              if (k) cleared.add(k);
            }
          }

          // Pass 2: capture latest uncleared failure per object
          for (const ob of objsAll) {
            const k = getObjKey(ob);
            if (!k) continue;
            if (cleared.has(k)) continue;
            if (latestFailByKey.has(k)) continue;
            if (!hasFailedAttempts(ob)) continue;

            const msg = combineFailedAttempts(ob?.localSnapshotInfo?.failedAttempts);
            if (!msg) continue;

            const o = ob.object || {};
            let hostName = "";
            if (o.sourceId && idToName.has(String(o.sourceId))) {
              hostName = idToName.get(String(o.sourceId));
            }

            latestFailByKey.set(k, {
              Environment: o.environment ? String(o.environment) : wi.pgEnv,
              Cluster: wi.clusterName,
              ProtectionGroup: wi.pgName,
              Host: hostName,
              ObjectType: o.objectType ? String(o.objectType) : "UnknownType",
              ObjectName: o.name ? String(o.name) : "",
              RunType: rType,
              EndTimeET: endTimeET,
              FailedMessage: msg,
            });
          }
        }

        for (const v of latestFailByKey.values()) out.push(v);
      }
    }

    // final dedup safety
    const dedup = new Map();
    for (const r of out) {
      const key = `${r.Environment}|${r.Cluster}|${r.ProtectionGroup}|${r.RunType}|${r.Host}|${r.ObjectType}|${r.ObjectName}`;
      const prev = dedup.get(key);
      if (!prev || String(r.EndTimeET) > String(prev.EndTimeET)) dedup.set(key, r);
    }

    return Array.from(dedup.values()).sort((a, b) => {
      const c = String(a.Cluster).localeCompare(String(b.Cluster));
      if (c) return c;
      const p = String(a.ProtectionGroup).localeCompare(String(b.ProtectionGroup));
      if (p) return p;
      const e = String(a.Environment).localeCompare(String(b.Environment));
      if (e) return e;
      const rt = String(a.RunType).localeCompare(String(b.RunType));
      if (rt) return rt;
      return String(b.EndTimeET).localeCompare(String(a.EndTimeET));
    });
  }

  function toMarkdownTable(failures) {
    if (!failures.length) return "✅ No backup failures found across all clusters.";
    const cols = [
      "Environment",
      "Cluster",
      "ProtectionGroup",
      "Host",
      "ObjectType",
      "ObjectName",
      "RunType",
      "EndTimeET",
      "FailedMessage",
    ];
    const lines = [];
    lines.push("### Cohesity Backup Failures — All Clusters");
    lines.push(`Total failures: **${failures.length}**`);
    lines.push("");
    lines.push(`| ${cols.join(" | ")} |`);
    lines.push(`| ${cols.map(() => "---").join(" | ")} |`);
    for (const r of failures) {
      const row = [
        r.Environment,
        r.Cluster,
        r.ProtectionGroup,
        r.Host || "",
        r.ObjectType,
        r.ObjectName,
        r.RunType,
        r.EndTimeET,
        r.FailedMessage,
      ].map(cleanMsg);
      lines.push(`| ${row.join(" | ")} |`);
    }
    return lines.join("\n");
  }

  function toIncidentTextCreate(failures, markdownTable) {
    const d = etDateYYYYMMDD();
    if (!failures.length) return `Cohesity Backup Failures (${d})\n\nNo failures detected.`;
    return `Cohesity Backup Failures (${d})\n\n${markdownTable}`;
  }

  function toIncidentTextUpdate(failures, markdownTable) {
    const d = etDateYYYYMMDD();
    if (!failures.length) return `Cohesity Backup Failures (${d})\n\nUpdate: No failures detected.`;
    return `Cohesity Backup Failures (${d}) — Update\n\n${markdownTable}`;
  }

  // -------------------------------
  // Run + return (shape preserved)
  // -------------------------------
  const failures = await collectAllFailures();
  const markdownTable = toMarkdownTable(failures);

  const d = etDateYYYYMMDD();
  const correlationId = `Cohesity_Backup_Failures_${d}`;
  const snow_query = `correlation_id=${correlationId}`;

  return {
    authMode: "vault",

    // debug-safe extra so you can confirm chaining without breaking SNOW steps
    pgWorkItemsCount,

    count: failures.length,
    failures,

    incidentText_create: toIncidentTextCreate(failures, markdownTable),
    incidentText_update: toIncidentTextUpdate(failures, markdownTable),

    markdownTable,
    markdownEmail: markdownTable,

    snow_query,
    snow_short_description: `Cohesity Backup Failures (${d})`,
    snow_description_create: toIncidentTextCreate(failures, markdownTable),
    snow_description_update: toIncidentTextUpdate(failures, markdownTable),
  };
}
