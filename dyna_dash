export default async function () {
  log.info("üöÄ Starting Cohesity Helios Capacity + Garbage Data Dashboard (native runtime)");

  // --- 1Ô∏è‚É£ Load API key from Dynatrace Credentials Vault ---
  const creds = await execution.credentials.get('cohesity-helios-api-key');
  const apiKey = creds?.value || creds?.token || creds?.password;
  if (!apiKey) throw new Error("‚ùå API key not found or inaccessible in credentials vault");

  // --- 2Ô∏è‚É£ Basic setup ---
  const baseUrl = "https://helios.cohesity.com";
  const oneTiB = 1099511627776;
  const headers = { accept: "application/json", apiKey };

  // --- 3Ô∏è‚É£ Get cluster list ---
  log.info("üîπ Fetching clusters...");
  const clusterResp = await http.get(`${baseUrl}/v2/mcm/cluster-mgmt/info`, { headers });
  if (clusterResp.status !== 200) throw new Error(`Cluster fetch failed (${clusterResp.status})`);

  const clusters = clusterResp.data?.cohesityClusters ?? [];
  log.info(`‚úÖ Found ${clusters.length} clusters`);

  const results = [];

  // --- 4Ô∏è‚É£ For each cluster ---
  for (const c of clusters) {
    const name = c.ClusterName;
    const id = c.ClusterId;
    log.info(`üìä Processing ${name}`);

    const h = { accept: "application/json", apiKey, accessClusterId: id };

    // --- Garbage data ---
    const body = {
      schemaName: "ApolloV2ClusterStats",
      metricName: "EstimatedGarbageBytes",
      startTimeMsecs: "2",
      entityId: `cluster name (ID ${id})`,
      rollupFunction: "latest",
      rollupIntervalSecs: "30",
      metricUnitType: "0",
      range: "day"
    };

    const garbage = await http.post(`${baseUrl}/irisservices/api/v1/public/statistics/timeSeriesStats`, {
      headers: h,
      body: JSON.stringify(body)
    });
    if (garbage.status !== 200) {
      log.warn(`‚ö†Ô∏è Garbage data fetch failed for ${name}`);
      continue;
    }

    const g = garbage.data;
    const last = g.dataPointVec?.slice(-1)[0];
    const bytes = last?.data?.int64Value ?? 0;
    const gb = +(bytes / (1024 ** 3)).toFixed(2);
    const tb = +(bytes / (1024 ** 4)).toFixed(4);

    // --- Capacity data ---
    const capacity = await http.get(`${baseUrl}/irisservices/api/v1/public/stats/storage`, { headers: h });
    if (capacity.status !== 200) {
      log.warn(`‚ö†Ô∏è Capacity fetch failed for ${name}`);
      continue;
    }

    const s = capacity.data;
    const totalTiB = +(s.totalCapacityBytes / oneTiB).toFixed(1);
    const usedTiB  = +(s.localUsageBytes / oneTiB).toFixed(1);
    const availTiB = +(s.localAvailableBytes / oneTiB).toFixed(1);
    const consumed = +((s.localUsageBytes / s.totalCapacityBytes) * 100).toFixed(1);

    results.push({
      Cluster: name,
      Garbage_GB: gb,
      Garbage_TB: tb,
      Total_TiB: totalTiB,
      Used_TiB: usedTiB,
      Available_TiB: availTiB,
      Consumed_Percent: consumed
    });

    // --- Emit custom metrics for dashboards ---
    await metrics.emit('custom.cohesity.cluster.garbage.GB', gb, { cluster: name });
    await metrics.emit('custom.cohesity.cluster.garbage.TB', tb, { cluster: name });
    await metrics.emit('custom.cohesity.cluster.capacity.totalTiB', totalTiB, { cluster: name });
    await metrics.emit('custom.cohesity.cluster.capacity.usedTiB', usedTiB, { cluster: name });
    await metrics.emit('custom.cohesity.cluster.capacity.availableTiB', availTiB, { cluster: name });
    await metrics.emit('custom.cohesity.cluster.capacity.percentUsed', consumed, { cluster: name });

    log.info(`‚úÖ ${name}: ${consumed}% used (${usedTiB}/${totalTiB} TiB), Garbage ${gb} GB`);
  }

  // --- 5Ô∏è‚É£ Final log summary ---
  log.info("üìÑ Summary:");
  log.info(JSON.stringify(results, null, 2));

  return { clusters: results };
}
