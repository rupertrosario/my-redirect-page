export default async function () {
  console.log("üöÄ Cohesity Helios ‚Äì Capacity + Garbage via timeSeriesStats (GET-only version)");

  // üîê Paste your working Helios API key here
  const apiKey  = "PASTE_YOUR_API_KEY_HERE";
  const baseUrl = "https://helios.cohesity.com";
  const oneTiB  = 1099511627776;
  const commonHeaders = { accept: "application/json", apiKey };

  // 1Ô∏è‚É£ Fetch cluster list
  const listResp = await fetch(`${baseUrl}/v2/mcm/cluster-mgmt/info`, { headers: commonHeaders });
  console.log(`‚û°Ô∏è Cluster list HTTP ${listResp.status}`);
  if (listResp.status !== 200) throw new Error(`‚ùå Failed to fetch clusters (HTTP ${listResp.status})`);

  const listJson = await listResp.json();
  const clusters = listJson?.cohesityClusters?.map(c => ({
    clusterName: c.clusterName,
    clusterId: c.clusterId
  })) || [];

  if (clusters.length === 0) {
    console.log("‚ö†Ô∏è No clusters returned ‚Äî check key scope or region.");
    return { clusters: [] };
  }

  const results = [];

  // 2Ô∏è‚É£ For each cluster: get garbage + capacity
  for (const { clusterName, clusterId } of clusters) {
    if (!clusterName || !clusterId) continue;

    console.log(`üìä Processing cluster: ${clusterName} (ID: ${clusterId})`);
    const h = { ...commonHeaders, accessClusterId: String(clusterId) };

    // --- Garbage Data ---
    const params = new URLSearchParams({
      schemaName: "ApolloV2ClusterStats",
      metricName: "EstimatedGarbageBytes",
      startTimeMsecs: "2",
      entityId: `cluster name (ID ${clusterId})`,
      rollupFunction: "latest",
      rollupIntervalSecs: "30",
      metricUnitType: "0",
      range: "day"
    });

    const tsUrl = `${baseUrl}/irisservices/api/v1/public/statistics/timeSeriesStats?${params.toString()}`;
    console.log(`üîó Garbage URL ‚Üí ${tsUrl}`);

    const tsResp = await fetch(tsUrl, { headers: h });
    if (tsResp.status !== 200) {
      console.log(`‚ö†Ô∏è Garbage stats fetch failed for ${clusterName} (${tsResp.status})`);
      continue;
    }

    const tsJson = await tsResp.json();
    const latest = Array.isArray(tsJson?.dataPointVec)
      ? tsJson.dataPointVec[tsJson.dataPointVec.length - 1]
      : undefined;

    const garbageBytes = latest?.data?.int64Value ?? 0;
    const garbageGB = +(garbageBytes / (1024 ** 3)).toFixed(2);
    const garbageTB = +(garbageBytes / (1024 ** 4)).toFixed(3);

    // --- Capacity Data ---
    const capResp = await fetch(`${baseUrl}/irisservices/api/v1/public/stats/storage`, { headers: h });
    if (capResp.status !== 200) {
      console.log(`‚ö†Ô∏è Capacity fetch failed for ${clusterName} (${capResp.status})`);
      continue;
    }

    const s = await capResp.json();
    const totalTiB = +(s.totalCapacityBytes / oneTiB).toFixed(2);
    const usedTiB  = +(s.localUsageBytes / oneTiB).toFixed(2);
    const availTiB = +(s.localAvailableBytes / oneTiB).toFixed(2);
    const consumed = +((s.localUsageBytes / s.totalCapacityBytes) * 100).toFixed(2);

    results.push({
      clusterName,
      clusterId,
      totalTiB,
      usedTiB,
      availTiB,
      consumedPercent: consumed,
      garbageGB,
      garbageTB
    });

    console.log(`‚úÖ ${clusterName}: ${consumed}% used (${usedTiB}/${totalTiB} TiB), Garbage ${garbageGB} GB (${garbageTB} TB)`);
  }

  // 3Ô∏è‚É£ Summary
  console.log("üìÑ Final Summary:");
  console.log(JSON.stringify(results, null, 2));

  // Return output for dashboard/workflow result
  return { clusters: results };
}
