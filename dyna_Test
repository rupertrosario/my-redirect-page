// ðŸš€ Cohesity Helios â€“ Read-only capacity + garbage (sorted + thresholds + GB/TB in report)
export default async function () {
  const apiKey  = "PASTE_YOUR_API_KEY_HERE";
  const baseUrl = "https://helios.cohesity.com";
  const oneTiB  = 1099511627776;
  const headers = { accept: "application/json", apiKey };

  // 1) Get clusters
  const listResp = await fetch(`${baseUrl}/v2/mcm/cluster-mgmt/info`, { method: "GET", headers });
  if (listResp.status !== 200) throw new Error(`âŒ Cluster list failed (${listResp.status})`);
  const clusters = (await listResp.json())?.cohesityClusters || [];
  if (!clusters.length) {
    const emptyReport = "ðŸ“Š **Cohesity Cluster Capacity Report**\n\n_No clusters returned._";
    return { clusters: [], report: emptyReport };
  }

  // 2) Per-cluster: fetch garbage + capacity in parallel
  const stats = await Promise.all(clusters.map(async ({ clusterName, clusterId }) => {
    const h = { ...headers, accessClusterId: String(clusterId) };
    const safeName = clusterName.replace(/\s+/g, '');
    const entityId = `${safeName}+(ID+${clusterId})`; // working format

    const tsUrl =
      `${baseUrl}/irisservices/api/v1/public/statistics/timeSeriesStats` +
      `?schemaName=ApolloV2ClusterStats` +
      `&metricName=EstimatedGarbageBytes` +
      `&startTimeMsecs=2` +
      `&entityId=${entityId}` +
      `&rollupFunction=latest` +
      `&rollupIntervalSecs=30` +
      `&metricUnitType=0` +
      `&range=day`;
    const capUrl = `${baseUrl}/irisservices/api/v1/public/stats/storage`;

    const [tsResp, capResp] = await Promise.all([
      fetch(tsUrl,  { method: "GET", headers: h }),
      fetch(capUrl, { method: "GET", headers: h })
    ]);

    // Garbage
    let garbageGB = 0, garbageTB = 0;
    if (tsResp.status === 200) {
      const tsJson = await tsResp.json();
      const vec = tsJson?.dataPointVec || [];
      const latest = vec.length ? vec[vec.length - 1] : undefined;
      const bytes = latest?.data?.int64Value ?? 0;
      garbageGB = +(bytes / (1024 ** 3)).toFixed(2);
      garbageTB = +(bytes / (1024 ** 4)).toFixed(3);
    }

    // Capacity
    if (capResp.status !== 200) return null;
    const s = await capResp.json();
    const totalTiB = +(s.totalCapacityBytes  / oneTiB).toFixed(2);
    const usedTiB  = +(s.localUsageBytes     / oneTiB).toFixed(2);
    const availTiB = +(s.localAvailableBytes / oneTiB).toFixed(2);
    const consumedPercent = +((s.localUsageBytes / s.totalCapacityBytes) * 100).toFixed(2);

    return {
      clusterName, clusterId,
      totalTiB, usedTiB, availTiB,
      consumedPercent,
      garbageGB, garbageTB
    };
  }));

  // Drop nulls and sort by clusterName
  const rows = stats.filter(Boolean).sort((a, b) => a.clusterName.localeCompare(b.clusterName));

  // Status badge for % used
  const badge = (p) => (p >= 80 ? "ðŸ”´" : (p > 70 ? "ðŸŸ¡" : "ðŸŸ¢"));

  // 3) Build Markdown table
  const header = [
    "ðŸ“Š **Cohesity Cluster Capacity Report**",
    "",
    "| Cluster | Used TiB | Avail TiB | % Used | Status | Garbage GB | Garbage TB |",
    "|--------|----------:|----------:|-------:|:------:|-----------:|-----------:|"
  ].join("\n");

  const body = rows.map(c =>
    `| ${c.clusterName} | ${c.usedTiB} | ${c.availTiB} | ${c.consumedPercent}% | ${badge(c.consumedPercent)} | ${c.garbageGB} | ${c.garbageTB} |`
  ).join("\n");

  const footer = [
    "",
    `_Total clusters: ${rows.length}_`
  ].join("\n");

  const report = [header, body, footer].join("\n");

  // 4) Return raw + report
  return { clusters: rows, report };
}
