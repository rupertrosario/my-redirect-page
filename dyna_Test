// ðŸš€ Cohesity Helios â€“ Read-only capacity + garbage (no metrics), returns Markdown table for email
export default async function () {
  const apiKey  = "PASTE_YOUR_API_KEY_HERE";   // Helios API key
  const baseUrl = "https://helios.cohesity.com";
  const oneTiB  = 1099511627776;
  const headers = { accept: "application/json", apiKey };

  // 1) Get clusters
  const listResp = await fetch(`${baseUrl}/v2/mcm/cluster-mgmt/info`, { method: "GET", headers });
  if (listResp.status !== 200) throw new Error(`âŒ Cluster list failed (${listResp.status})`);
  const clusters = (await listResp.json())?.cohesityClusters || [];
  if (!clusters.length) {
    const emptyReport = "ðŸ“Š **Cohesity Cluster Capacity Report**\n\n_No clusters returned._";
    return { clusters: [], report: emptyReport };
  }

  // 2) For each cluster, fetch garbage + capacity in parallel (fast)
  const stats = await Promise.all(clusters.map(async ({ clusterName, clusterId }) => {
    const h = { ...headers, accessClusterId: String(clusterId) };
    const safeName = clusterName.replace(/\s+/g, '');
    const entityId = `${safeName}+(ID+${clusterId})`; // âœ… your proven-working format

    const tsUrl =
      `${baseUrl}/irisservices/api/v1/public/statistics/timeSeriesStats` +
      `?schemaName=ApolloV2ClusterStats` +
      `&metricName=EstimatedGarbageBytes` +
      `&startTimeMsecs=2` +
      `&entityId=${entityId}` +
      `&rollupFunction=latest` +
      `&rollupIntervalSecs=30` +
      `&metricUnitType=0` +
      `&range=day`;

    const capUrl = `${baseUrl}/irisservices/api/v1/public/stats/storage`;

    const [tsResp, capResp] = await Promise.all([
      fetch(tsUrl,  { method: "GET", headers: h }),
      fetch(capUrl, { method: "GET", headers: h })
    ]);

    // Garbage
    let garbageGB = 0, garbageTB = 0;
    if (tsResp.status === 200) {
      const tsJson = await tsResp.json();
      const vec = tsJson?.dataPointVec || [];
      const latest = vec.length ? vec[vec.length - 1] : undefined;
      const bytes = latest?.data?.int64Value ?? 0;
      garbageGB = +(bytes / (1024 ** 3)).toFixed(2);
      garbageTB = +(bytes / (1024 ** 4)).toFixed(3);
    }

    // Capacity
    if (capResp.status !== 200) return null;
    const s = await capResp.json();
    const totalTiB = +(s.totalCapacityBytes  / oneTiB).toFixed(2);
    const usedTiB  = +(s.localUsageBytes     / oneTiB).toFixed(2);
    const availTiB = +(s.localAvailableBytes / oneTiB).toFixed(2);
    const consumed = +((s.localUsageBytes / s.totalCapacityBytes) * 100).toFixed(2);

    return {
      clusterName, clusterId,
      totalTiB, usedTiB, availTiB,
      consumedPercent: consumed,
      garbageGB, garbageTB
    };
  }));

  const rows = stats.filter(Boolean); // drop any nulls

  // 3) Build Markdown table (no loops needed in email)
  const header = [
    "ðŸ“Š **Cohesity Cluster Capacity Report**",
    "",
    "| Cluster | Used TiB | Avail TiB | % Used | Garbage GB |",
    "|--------|----------:|----------:|-------:|-----------:|"
  ].join("\n");

  const body = rows.map(c =>
    `| ${c.clusterName} | ${c.usedTiB} | ${c.availTiB} | ${c.consumedPercent}% | ${c.garbageGB} |`
  ).join("\n");

  const footer = [
    "",
    `_Total clusters: ${rows.length}_`
  ].join("\n");

  const report = [header, body, footer].join("\n");

  // 4) Return raw data + prebuilt Markdown
  return { clusters: rows, report };
}
