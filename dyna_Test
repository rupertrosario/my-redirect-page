// üöÄ Cohesity Helios ‚Äì Fast Read-Only Cluster Capacity + Garbage (no metrics ingest)
export default async function () {
  const apiKey  = "PASTE_YOUR_API_KEY_HERE";    // Helios API key
  const baseUrl = "https://helios.cohesity.com";
  const oneTiB  = 1099511627776;
  const headers = { accept: "application/json", apiKey };

  // 1Ô∏è‚É£ Get clusters
  const listResp = await fetch(`${baseUrl}/v2/mcm/cluster-mgmt/info`, { method: "GET", headers });
  if (listResp.status !== 200) throw new Error(`‚ùå Cluster list failed (${listResp.status})`);
  const clusters = (await listResp.json())?.cohesityClusters || [];
  if (!clusters.length) {
    console.log("‚ö†Ô∏è No clusters found.");
    return { clusters: [] };
  }

  console.log(`üîç Found ${clusters.length} clusters. Fetching capacity & garbage...`);

  // 2Ô∏è‚É£ Process clusters in parallel (fast)
  const clusterStats = await Promise.all(clusters.map(async ({ clusterName, clusterId }) => {
    const h = { ...headers, accessClusterId: String(clusterId) };
    const safeName = clusterName.replace(/\s+/g, '');
    const entityId = `${safeName}+(ID+${clusterId})`;  // ‚úÖ your working format

    // --- URLs for garbage and capacity
    const tsUrl =
      `${baseUrl}/irisservices/api/v1/public/statistics/timeSeriesStats` +
      `?schemaName=ApolloV2ClusterStats` +
      `&metricName=EstimatedGarbageBytes` +
      `&startTimeMsecs=2` +
      `&entityId=${entityId}` +
      `&rollupFunction=latest` +
      `&rollupIntervalSecs=30` +
      `&metricUnitType=0` +
      `&range=day`;
    const capUrl = `${baseUrl}/irisservices/api/v1/public/stats/storage`;

    // --- Run both GETs at the same time
    const [tsResp, capResp] = await Promise.all([
      fetch(tsUrl, { method: "GET", headers: h }),
      fetch(capUrl, { method: "GET", headers: h })
    ]);

    // --- Garbage
    let garbageGB = 0, garbageTB = 0;
    if (tsResp.status === 200) {
      const tsJson = await tsResp.json();
      const vec = tsJson?.dataPointVec || [];
      const latest = vec.length ? vec[vec.length - 1] : undefined;
      const bytes = latest?.data?.int64Value ?? 0;
      garbageGB = +(bytes / (1024 ** 3)).toFixed(2);
      garbageTB = +(bytes / (1024 ** 4)).toFixed(3);
    } else {
      console.log(`‚ö†Ô∏è Garbage fetch failed for ${clusterName} (HTTP ${tsResp.status})`);
    }

    // --- Capacity
    if (capResp.status !== 200) {
      console.log(`‚ö†Ô∏è Capacity fetch failed for ${clusterName} (HTTP ${capResp.status})`);
      return null;
    }

    const s = await capResp.json();
    const totalTiB = +(s.totalCapacityBytes  / oneTiB).toFixed(2);
    const usedTiB  = +(s.localUsageBytes     / oneTiB).toFixed(2);
    const availTiB = +(s.localAvailableBytes / oneTiB).toFixed(2);
    const consumed = +((s.localUsageBytes / s.totalCapacityBytes) * 100).toFixed(2);

    console.log(`‚úÖ ${clusterName}: ${usedTiB}/${totalTiB} TiB used (${consumed}%) | Garbage ${garbageGB} GB`);

    return {
      clusterName, clusterId,
      totalTiB, usedTiB, availTiB,
      consumedPercent: consumed,
      garbageGB, garbageTB
    };
  }));

  const valid = clusterStats.filter(Boolean);

  // 3Ô∏è‚É£ Output summary
  console.log("üìÑ Final summary:");
  console.log(JSON.stringify(valid, null, 2));

  // ‚úÖ Return usable data for email or dashboards
  return { clusters: valid };
}
