// Fast minimal: Cohesity Helios READ-ONLY â†’ Dynatrace metrics ingest (parallelized)
import { metricsClient } from '@dynatrace-sdk/client-classic-environment-v2';

export default async function () {
  const apiKey  = "PASTE_YOUR_API_KEY_HERE";
  const baseUrl = "https://helios.cohesity.com";
  const oneTiB  = 1099511627776;
  const headers = { accept: "application/json", apiKey };

  // 1) Get clusters
  const listResp = await fetch(`${baseUrl}/v2/mcm/cluster-mgmt/info`, { method: "GET", headers });
  if (listResp.status !== 200) throw new Error(`Cluster list failed (${listResp.status})`);
  const clusters = (await listResp.json())?.cohesityClusters || [];
  if (!clusters.length) return { clusters: [] };

  // 2) Per-cluster work in parallel (and per-cluster GETs in parallel)
  const perClusterPromises = clusters.map(async ({ clusterName, clusterId }) => {
    const h = { ...headers, accessClusterId: String(clusterId) };

    // entityId in your proven-working format
    const safeName = clusterName.replace(/\s+/g, '');
    const entityId = `${safeName}+(ID+${clusterId})`;

    const tsUrl =
      `${baseUrl}/irisservices/api/v1/public/statistics/timeSeriesStats` +
      `?schemaName=ApolloV2ClusterStats` +
      `&metricName=EstimatedGarbageBytes` +
      `&startTimeMsecs=2` +
      `&entityId=${entityId}` +
      `&rollupFunction=latest` +
      `&rollupIntervalSecs=30` +
      `&metricUnitType=0` +
      `&range=day`;

    const capUrl = `${baseUrl}/irisservices/api/v1/public/stats/storage`;

    // Run both GETs together
    const [tsResp, capResp] = await Promise.all([
      fetch(tsUrl, { method: "GET", headers: h }),
      fetch(capUrl, { method: "GET", headers: h })
    ]);

    // Garbage
    let garbageGB = 0, garbageTB = 0;
    if (tsResp.status === 200) {
      const tsJson = await tsResp.json();
      const vec = tsJson?.dataPointVec || [];
      const latest = vec.length ? vec[vec.length - 1] : undefined;
      const bytes = latest?.data?.int64Value ?? 0;
      garbageGB = +(bytes / (1024 ** 3)).toFixed(2);
      garbageTB = +(bytes / (1024 ** 4)).toFixed(3);
    }

    // Capacity
    if (capResp.status !== 200) return null;
    const s = await capResp.json();
    const totalTiB = +(s.totalCapacityBytes  / oneTiB).toFixed(2);
    const usedTiB  = +(s.localUsageBytes     / oneTiB).toFixed(2);
    const availTiB = +(s.localAvailableBytes / oneTiB).toFixed(2);
    const consumed = +((s.localUsageBytes / s.totalCapacityBytes) * 100).toFixed(2);

    // Build result + metric lines for this cluster
    const dims = `clusterName="${clusterName.replace(/"/g, '\\"')}",clusterId="${clusterId}"`;
    const lines = [
      `cohesity.capacity.total.tib,${dims} ${totalTiB}`,
      `cohesity.capacity.used.tib,${dims} ${usedTiB}`,
      `cohesity.capacity.avail.tib,${dims} ${availTiB}`,
      `cohesity.capacity.consumed.percent,${dims} ${consumed}`,
      `cohesity.garbage.gb,${dims} ${garbageGB}`,
      `cohesity.garbage.tb,${dims} ${garbageTB}`
    ];

    return {
      result: { clusterName, clusterId, totalTiB, usedTiB, availTiB, consumedPercent: consumed, garbageGB, garbageTB },
      lines
    };
  });

  const perCluster = await Promise.all(perClusterPromises);
  const valid = perCluster.filter(Boolean);

  const results = valid.map(v => v.result);
  const lines = valid.flatMap(v => v.lines);

  // 3) Ingest to Dynatrace (if permitted)
  if (lines.length) {
    try {
      await metricsClient.ingest({ body: lines.join('\n') });
    } catch (e) {
      // print exact API message if present
      let msg = e?.message || String(e);
      try {
        const parsed = JSON.parse(msg);
        msg = parsed?.error?.message || parsed?.message || msg;
      } catch {}
      console.log(`Metrics ingest error: ${msg}`);
    }
  }

  return { clusters: results };
}
