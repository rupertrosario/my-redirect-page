import { credentialVaultClient } from "@dynatrace-sdk/client-classic-environment-v2";

/**
 * Cohesity Cluster Health Tiles — System → Health → Components (GET-only)
 * - ALL clusters from /v2/mcm/cluster-mgmt/info
 * - Alerts from /v2/mcm/alerts (dedupe by alertsList[].id, ignore dedupCount)
 * - Email-safe markdown tables (Hardware / Maintenance / Data Service + combined)
 * - FAIL-CLOSED:
 *    - isConnectedToHelios === false  -> ⚠️NO_DATA (all cells, all sections)
 *    - /mcm/alerts batch call fails   -> ⚠️NO_DATA for clusters in that batch (that section)
 */

export default async function () {
  const baseUrl = "https://helios.cohesity.com";

  // ==============================
  // AUTH (vault id)
  // ==============================
  const vaultId = "credentials_vault-312312";
  const d2 = await credentialVaultClient.getCredentialsDetails({ id: vaultId });
  const apiKey = (d2?.token || d2?.password || "").trim();
  if (!apiKey) throw new Error("No Helios API key available (empty token/password).");

  const commonHeaders = { accept: "application/json", apiKey };

  // ==============================
  // PERF / LIMITS
  // ==============================
  const CONCURRENCY = 8;
  const CLUSTER_BATCH_SIZE = 25;
  const MAX_ALERTS_PER_CALL = 5000;
  const MAX_PAGES_PER_BATCH = 50;

  // Rolling window to avoid 10k+ active alerts
  const WINDOW_HOURS = 24;

  // ==============================
  // CATEGORY LISTS (sorted)
  // ==============================
  const HW_Cats = [
    "kDisk","kNode","kCluster","kChassis","kPowerSupply","kCPU","kMemory","kTemperature",
    "kFan","kNIC","kFirmware","kNodeHealth","kOperatingSystem","kStorageDevice","kStoragePool"
  ].sort();

  const MAINT_Cats = [
    "kHelios","kAppMarketPlace","kSystemService","kLicense","kSecurity","kUpgrade",
    "kClusterManagement","kAuditLog","kNetworking","kConfiguration","kStorageUsage",
    "kFaultTolerance","kGeneralSoftwareFailure"
  ].sort();

  const DS_Cats = [
    "kDataPath","kDataSourceConnector","kMetadata","kIndexing","kBackupRestore","kArchivalRestore",
    "kRemoteReplication","kQuota","kCDP","kViewFailover","kDisasterRecovery","kAgent","kNetBackup"
  ].sort();

  // ==============================
  // SYMBOLS
  // ==============================
  const SYM_OK = "✅";
  const SYM_C = "⛔";
  const SYM_W = "⚠️";
  const SYM_I = "ℹ️";
  const SYM_NO_DATA = `${SYM_W}NO_DATA`;

  // ==============================
  // HELPERS
  // ==============================
  const norm = (v) => (v === null || v === undefined ? "" : String(v).trim());
  const toArray = (v) => (!v ? [] : Array.isArray(v) ? v : [v]);
  const safeCell = (v) => (v === null || v === undefined ? "" : String(v).replace(/\|/g, " "));

  async function getJson(url, headers) {
    const resp = await fetch(url, { method: "GET", headers });
    if (!resp.ok) {
      let txt = "";
      try { txt = await resp.text(); } catch (_) {}
      throw new Error(`GET ${url} -> HTTP ${resp.status} ${txt}`.trim());
    }
    return resp.json();
  }

  function mdTable(headers, rows) {
    if (!rows.length) return "No clusters returned.";
    const head = `| ${headers.join(" | ")} |`;
    const sep = `| ${headers.map(() => "---").join(" | ")} |`;
    const body = rows.map((r) => `| ${headers.map((h) => safeCell(r[h] ?? "")).join(" | ")} |`);
    return [head, sep, ...body].join("\n");
  }

  function chunk(arr, n) {
    const out = [];
    for (let i = 0; i < arr.length; i += n) out.push(arr.slice(i, i + n));
    return out;
  }

  async function poolMap(items, worker, concurrency) {
    const results = new Array(items.length);
    let idx = 0;
    const runners = new Array(Math.min(concurrency, items.length)).fill(0).map(async () => {
      while (idx < items.length) {
        const cur = idx++;
        results[cur] = await worker(items[cur], cur);
      }
    });
    await Promise.all(runners);
    return results;
  }

  function cellFromCounts(c, w, i) {
    const cc = Number(c || 0);
    const ww = Number(w || 0);
    const ii = Number(i || 0);
    if (cc === 0 && ww === 0 && ii === 0) return SYM_OK;
    return `${SYM_C}${cc} ${SYM_W}${ww} ${SYM_I}${ii}`;
  }

  function nowUsecs() {
    return Date.now() * 1000;
  }

  function buildWindowUsecs(hours) {
    const end = nowUsecs();
    const start = end - hours * 60 * 60 * 1_000_000;
    return { startTimeUsecs: Math.floor(start), endTimeUsecs: Math.floor(end) };
  }

  function normalizeMcmAlertsPayload(payload) {
    const alertsList = toArray(payload?.alertsList);
    const nextCursor =
      payload?.nextCursor ?? payload?.cursor ?? payload?.next_cursor ?? payload?.next ?? null;
    const nextPageToken =
      payload?.nextPageToken ?? payload?.pageToken ?? payload?.next_page_token ?? payload?.continuationToken ?? null;
    const hasMore = Boolean(payload?.hasMore || payload?.has_more);
    return { alertsList, nextCursor, nextPageToken, hasMore };
  }

  // ==============================
  // 1) CLUSTERS
  // ==============================
  const clu = await getJson(`${baseUrl}/v2/mcm/cluster-mgmt/info`, commonHeaders);

  const clusters = toArray(clu?.cohesityClusters)
    .map((c) => ({
      clusterName: norm(c?.clusterName),
      clusterId: norm(c?.clusterId),
      // IMPORTANT: treat missing as connected; only explicit false is disconnected
      isConnectedToHelios: c?.isConnectedToHelios !== false,
    }))
    .filter((c) => c.clusterName && c.clusterId)
    .sort((a, b) => a.clusterName.localeCompare(b.clusterName));

  if (!clusters.length) throw new Error("No clusters returned from /v2/mcm/cluster-mgmt/info");

  const clusterIdToName = new Map(clusters.map((c) => [String(c.clusterId), c.clusterName]));
  const connectedClusterIds = clusters.filter((c) => c.isConnectedToHelios).map((c) => String(c.clusterId));
  const disconnectedClusterIds = new Set(clusters.filter((c) => !c.isConnectedToHelios).map((c) => String(c.clusterId)));

  // ==============================
  // 2) /v2/mcm/alerts (DEDUP + AGG)
  // ==============================
  const { startTimeUsecs, endTimeUsecs } = buildWindowUsecs(WINDOW_HOURS);

  // IMPORTANT: arrays must be encoded as repeated query params (per docs)
  function buildAlertsUrl({ bucket, clusterIds, cursor, pageToken }) {
    const u = new URL(`${baseUrl}/v2/mcm/alerts`);

    u.searchParams.set("alertIdList", "");

    // alertStateList: array-of-strings => repeat param
    ["kOpen", "kNote"].forEach((s) => u.searchParams.append("alertStateList", s));

    // clusterIdentifiers: array-of-strings => repeat param
    clusterIds.forEach((id) => u.searchParams.append("clusterIdentifiers", String(id)));

    // alertTypeBucketList: array-of-strings => repeat param
    u.searchParams.append("alertTypeBucketList", bucket);

    // time window + cap
    u.searchParams.set("startTimeUsecs", String(startTimeUsecs));
    u.searchParams.set("endTimeUsecs", String(endTimeUsecs));
    u.searchParams.set("maxAlerts", String(MAX_ALERTS_PER_CALL));

    if (cursor) u.searchParams.set("cursor", String(cursor));
    if (pageToken) u.searchParams.set("pageToken", String(pageToken));

    return u.toString();
  }

  // Aggregation store: bucket -> clusterId -> category -> {c,w,i}
  function ensureAgg(agg, bucket, clusterId, category) {
    if (!agg.has(bucket)) agg.set(bucket, new Map());
    const b = agg.get(bucket);
    if (!b.has(clusterId)) b.set(clusterId, new Map());
    const c = b.get(clusterId);
    if (!c.has(category)) c.set(category, { c: 0, w: 0, i: 0 });
    return c.get(category);
  }

  async function fetchBucketAggregates(bucket) {
    const agg = new Map(); // bucket -> ...
    const failedClusterIds = new Set();

    const batches = chunk(connectedClusterIds, CLUSTER_BATCH_SIZE);

    await poolMap(
      batches,
      async (clusterIdBatch) => {
        try {
          let pages = 0;
          let cursor = null;
          let pageToken = null;

          // DEDUP within this batch+bucket
          const seen = new Set();

          while (pages < MAX_PAGES_PER_BATCH) {
            pages += 1;

            const url = buildAlertsUrl({ bucket, clusterIds: clusterIdBatch, cursor, pageToken });
            const payload = await getJson(url, commonHeaders);
            const { alertsList, nextCursor, nextPageToken, hasMore } = normalizeMcmAlertsPayload(payload);

            for (const a of alertsList) {
              const id = norm(a?.id);
              if (!id || seen.has(id)) continue;
              seen.add(id);

              const clusterId = String(a?.clusterId ?? "");
              const alertBucket = norm(a?.alertTypeBucket);
              const category = norm(a?.alertCategory);
              const severity = norm(a?.severity);

              if (!clusterId || !clusterIdToName.has(clusterId)) continue;
              if (alertBucket !== bucket) continue;
              if (!category) continue;

              const cell = ensureAgg(agg, bucket, clusterId, category);
              if (severity === "kCritical") cell.c += 1;
              else if (severity === "kWarning") cell.w += 1;
              else if (severity === "kInfo") cell.i += 1;
            }

            if (nextCursor) { cursor = nextCursor; pageToken = null; continue; }
            if (nextPageToken) { pageToken = nextPageToken; cursor = null; continue; }
            if (hasMore) break; // hasMore without token -> stop
            break;
          }
        } catch (_) {
          // FAIL-CLOSED for this bucket on this batch
          for (const cid of clusterIdBatch) failedClusterIds.add(String(cid));
        }
      },
      CONCURRENCY
    );

    return { agg, failedClusterIds };
  }

  const bucketResults = {
    kHardware: await fetchBucketAggregates("kHardware"),
    kMaintenance: await fetchBucketAggregates("kMaintenance"),
    kDataService: await fetchBucketAggregates("kDataService"),
  };

  function getCounts(bucket, clusterId, category) {
    const { agg } = bucketResults[bucket] || {};
    const b = agg?.get(bucket);
    const c = b?.get(String(clusterId));
    const v = c?.get(category);
    return v || { c: 0, w: 0, i: 0 };
  }

  function clusterIsNoDataForBucket(bucket, clusterId) {
    const failed = bucketResults[bucket]?.failedClusterIds;
    return disconnectedClusterIds.has(String(clusterId)) || (failed && failed.has(String(clusterId)));
  }

  // ==============================
  // 3) Build markdown sections
  // ==============================
  function buildSection(bucket, cats) {
    const rows = [];

    for (const cl of clusters) {
      const row = { ClusterName: cl.clusterName };

      if (clusterIsNoDataForBucket(bucket, cl.clusterId)) {
        for (const cat of cats) row[cat] = SYM_NO_DATA;
        rows.push(row);
        continue;
      }

      for (const cat of cats) {
        const { c, w, i } = getCounts(bucket, cl.clusterId, cat);
        row[cat] = cellFromCounts(c, w, i);
      }

      rows.push(row);
    }

    rows.sort((a, b) => String(a.ClusterName).localeCompare(String(b.ClusterName)));
    return mdTable(["ClusterName", ...cats], rows);
  }

  // ==============================
  // NOTE / HEADER (exact wording)
  // ==============================
  const note = [
    "### Cohesity Hardware Health Check",
    "This report mimics the System → Health → Components view for each Cohesity cluster.",
    "**Legend:** ✅ Healthy | ⛔<N> Critical | ⚠️<N> Warning | ℹ️<N> Info | ⚠️NO_DATA Unreachable",
  ].join("\n\n");

  const markdownHardware = `\n**Hardware**\n${buildSection("kHardware", HW_Cats)}`;
  const markdownMaintenance = `\n**Maintenance**\n${buildSection("kMaintenance", MAINT_Cats)}`;
  const markdownDataService = `\n**Data Service**\n${buildSection("kDataService", DS_Cats)}`;

  const markdown = [note, markdownHardware, markdownMaintenance, markdownDataService].join("\n\n");

  return { note, markdownHardware, markdownMaintenance, markdownDataService, markdown };
}
