// Cohesity Helios – Backup Failures (All Environments, per Protection Group)
// Only failures with NO later successful backup
// - Dynatrace classic credential vault (name -> id -> manual)
// - READ-ONLY: all Helios calls are HTTP GET
//
// Output:
// {
//   authMode: "vault-name" | "vault-id" | "manual",
//   count: <number>,
//   failures: [
//     {
//       Environment,
//       Cluster,
//       ProtectionGroup,
//       RunType,
//       StartTime,
//       EndTime,
//       Status,
//       FailedMessage
//     }
//   ],
//   markdownTable: "<markdown table string>"
// }

import { credentialVaultClient } from "@dynatrace-sdk/client-classic-environment-v2";

export default async function () {
  const baseUrl = "https://helios.cohesity.com";

  // ------------------------------
  // 1) Credential vault: name -> id -> manual
  // ------------------------------
  const vaultName = "Cohesity_API_Key";
  const vaultId   = "credentials_vault-312312";

  let apiKey   = null;
  let authMode = "vault-name";

  async function getKeyByName(name) {
    const all = await credentialVaultClient.getCredentials();
    const found = all.credentials.find(c => c.name === name);
    if (!found) return null;
    const detail = await credentialVaultClient.getCredentialsDetails({ id: found.id });
    console.log(`✓ Helios key from vault (name): ${found.name}`);
    return detail?.token || detail?.password || null;
  }

  try {
    apiKey = await getKeyByName(vaultName);
    if (!apiKey) throw new Error("not-found");
  } catch {
    try {
      const detail = await credentialVaultClient.getCredentialsDetails({ id: vaultId });
      apiKey       = detail?.token || detail?.password || null;
      authMode     = "vault-id";
      console.log(`✓ Helios key from vault (id): ${detail?.name || vaultId}`);
    } catch {
      authMode = "manual";
      apiKey   = "PASTE_YOUR_API_KEY_HERE";  // last resort, still GET-only
      console.log("⚠️ Using manual Helios API key (fallback)");
    }
  }

  if (!apiKey) {
    throw new Error("No Helios API key available (vault + manual failed).");
  }

  const commonHeaders = { accept: "application/json", apiKey };

  // ------------------------------
  // 2) Helpers
  // ------------------------------
  async function getJson(url, headers = {}) {
    const resp = await fetch(url, { method: "GET", headers });
    if (!resp.ok) {
      let txt = "";
      try { txt = await resp.text(); } catch {}
      throw new Error(`GET ${url} -> HTTP ${resp.status} ${txt}`);
    }
    return resp.json();
  }

  function usecsToDateString(usecs) {
    if (!usecs) return null;
    const ms = Number(usecs) / 1000;  // microseconds -> ms
    if (!Number.isFinite(ms)) return null;
    return new Date(ms).toISOString();
  }

  function cleanMessage(msg) {
    if (msg == null) return "";
    if (Array.isArray(msg)) msg = msg.join(" | ");
    msg = String(msg);
    return msg.replace(/[\r\n]+/g, " ").replace(/,/g, " ").replace(/"/g, "'").trim();
  }

  function buildQuery(params) {
    const usp = new URLSearchParams();
    for (const [k, v] of Object.entries(params)) {
      if (v === undefined || v === null) continue;
      if (Array.isArray(v)) {
        v.forEach(val => usp.append(k, String(val)));
      } else {
        usp.append(k, String(v));
      }
    }
    return usp.toString();
  }

  function toInfoArray(localBackupInfo) {
    if (!localBackupInfo) return [];
    return Array.isArray(localBackupInfo) ? localBackupInfo : [localBackupInfo];
  }

  // environment mapping – same idea as your PS envMap
  const ENV_LABELS = {
    kOracle:        "Oracle",
    kSQL:           "SQL",
    kPhysical:      "Physical",
    kGenericNas:    "NAS",
    kIsilon:        "NAS",
    kHyperV:        "HyperV",
    kAcropolis:     "Acropolis",
    kRemoteAdapter: "RemoteAdapter"
  };

  function mapEnvironment(pg) {
    let envRaw = pg.environment;
    if (!envRaw && Array.isArray(pg.environmentTypes) && pg.environmentTypes.length > 0) {
      envRaw = pg.environmentTypes[0];
    }
    if (!envRaw) return "Unknown";
    return ENV_LABELS[envRaw] || envRaw;
  }

  // Only treat this as a "failure" if it’s an actual failure, not Running/Accepted/etc.
  function isFailedStatus(status) {
    return status === "Failed";  // you can extend if Cohesity uses more failure strings
  }

  function isSuccessStatus(status) {
    return status === "Succeeded" || status === "SucceededWithWarning";
  }

  // ------------------------------
  // 3) Per-PG collector:
  //    - Look at last 30 runs (fast enough)
  //    - Find latest FAILED run
  //    - If there is any SUCCESS after that → ignore
  //    - Else → include that failed run
  // ------------------------------
  async function collectPgFailure(clusterName, headers, pg) {
    const pgId   = pg.id;
    const pgName = pg.name || "Unknown PG";
    const envLbl = mapEnvironment(pg);

    const runQuery = buildQuery({
      numRuns: 30,                      // matches your "numRuns=30" ask
      excludeNonRestorableRuns: false,
      includeObjectDetails: false       // keep payload small
    });

    let runData;
    try {
      runData = await getJson(
        `${baseUrl}/v2/data-protect/protection-groups/${encodeURIComponent(pgId)}/runs?${runQuery}`,
        headers
      );
    } catch {
      // One bad PG shouldn’t kill the report
      return [];
    }

    const runs = runData.runs || [];
    if (!runs.length) return [];

    // Flatten runs into simple records (PG-level, using first localBackupInfo)
    const records = [];
    for (const run of runs) {
      const infos = toInfoArray(run.localBackupInfo);
      if (!infos.length) continue;
      const info = infos[0];  // match your PS pattern

      const status = info.status || "Unknown";
      const runType = info.runType || "";
      const startUsecs = info.startTimeUsecs || 0;
      const endUsecs   = info.endTimeUsecs || 0;

      records.push({
        status,
        runType,
        startUsecs,
        endUsecs,
        startTimeStr: usecsToDateString(startUsecs),
        endTimeStr:   usecsToDateString(endUsecs),
        message:      cleanMessage(info.messages)
      });
    }

    if (!records.length) return [];

    // Sort by endTime ascending so we can reason about "later"
    records.sort((a, b) => (a.endUsecs || 0) - (b.endUsecs || 0));

    // Find latest FAILED run
    let latestFailed = null;
    for (let i = records.length - 1; i >= 0; i--) {
      if (isFailedStatus(records[i].status)) {
        latestFailed = records[i];
        break;
      }
    }
    if (!latestFailed) return [];  // no failed runs at all

    // Check if there is any SUCCESS after that failed run
    const failEnd = latestFailed.endUsecs || 0;
    let hasLaterSuccess = false;
    for (let i = 0; i < records.length; i++) {
      const r = records[i];
      if (!isSuccessStatus(r.status)) continue;
      if ((r.startUsecs || 0) > failEnd) {
        hasLaterSuccess = true;
        break;
      }
    }

    if (hasLaterSuccess) {
      // "failure resolved by later success" → exclude, as you requested
      return [];
    }

    // If we reach here:
    // - There is at least one Failed run
    // - No later Succeeded / SucceededWithWarning run
    // - We DO NOT include Running / Accepted at all
    return [{
      Environment:     envLbl,
      Cluster:         clusterName,
      ProtectionGroup: pgName,
      RunType:         latestFailed.runType,
      StartTime:       latestFailed.startTimeStr,
      EndTime:         latestFailed.endTimeStr,
      Status:          latestFailed.status,
      FailedMessage:   latestFailed.message
    }];
  }

  // ------------------------------
  // 4) Per-cluster collector (parallel over PGs)
  // ------------------------------
  async function collectClusterFailures(cluster) {
    const clusterName =
      cluster.name ||
      cluster.clusterName ||
      cluster.displayName ||
      `Unknown-${cluster.clusterId}`;

    const headers = { ...commonHeaders, accessClusterId: String(cluster.clusterId) };

    const pgQuery = buildQuery({
      isDeleted: false,
      isPaused: false,
      isActive: true
    });

    let pgData;
    try {
      pgData = await getJson(
        `${baseUrl}/v2/data-protect/protection-groups?${pgQuery}`,
        headers
      );
    } catch {
      return [];
    }

    const pgs = pgData.protectionGroups || [];
    if (!pgs.length) return [];

    // Parallelize PG-level /runs calls for speed
    const pgPromises = pgs.map(pg => collectPgFailure(clusterName, headers, pg));
    const results = await Promise.all(pgPromises);

    const allRows = [];
    for (const arr of results) {
      if (arr && arr.length) allRows.push(...arr);
    }
    return allRows;
  }

  // ------------------------------
  // 5) Collect all clusters, flatten, sort
  // ------------------------------
  async function collectAllFailures() {
    const clusterData = await getJson(
      `${baseUrl}/v2/mcm/cluster-mgmt/info`,
      commonHeaders
    );
    const clusters = clusterData.cohesityClusters || [];
    if (!clusters.length) return [];

    const clusterPromises = clusters.map(cluster => collectClusterFailures(cluster));
    const clusterResults  = await Promise.all(clusterPromises);

    const allRows = [];
    for (const arr of clusterResults) {
      if (arr && arr.length) allRows.push(...arr);
    }

    // Sort: Cluster, Environment, ProtectionGroup, EndTime (latest first)
    allRows.sort((a, b) => {
      const c1 = (a.Cluster || "").localeCompare(b.Cluster || "");
      if (c1 !== 0) return c1;
      const c2 = (a.Environment || "").localeCompare(b.Environment || "");
      if (c2 !== 0) return c2;
      const c3 = (a.ProtectionGroup || "").localeCompare(b.ProtectionGroup || "");
      if (c3 !== 0) return c3;
      const tA = a.EndTime ? new Date(a.EndTime).getTime() : 0;
      const tB = b.EndTime ? new Date(b.EndTime).getTime() : 0;
      return tB - tA;
    });

    return allRows;
  }

  // ------------------------------
  // 6) Markdown table for email
  // ------------------------------
  function toMarkdownTable(rows) {
    if (!rows || rows.length === 0) {
      return "✅ No backup failures found without a later successful run.";
    }

    const headers = [
      "Environment",
      "Cluster",
      "ProtectionGroup",
      "RunType",
      "StartTime",
      "EndTime",
      "Status",
      "FailedMessage"
    ];

    const headerRow = `| ${headers.join(" | ")} |`;
    const separator = `| ${headers.map(() => "---").join(" | ")} |`;

    const bodyRows = rows.map(r => {
      const vals = headers.map(h => {
        const v = r[h] ?? "";
        const s = String(v);
        return s.length > 300 ? s.slice(0, 297) + "..." : s;
      });
      return `| ${vals.join(" | ")} |`;
    });

    return [headerRow, separator, ...bodyRows].join("\n");
  }

  // ------------------------------
  // 7) Run + return
  // ------------------------------
  const failures      = await collectAllFailures();
  const markdownTable = toMarkdownTable(failures);

  return {
    authMode,
    count: failures.length,
    failures,
    markdownTable
  };
}
