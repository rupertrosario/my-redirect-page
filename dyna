// Dynatrace Workflow: Run JavaScript
// Requires: @dynatrace-sdk/client-classic-environment-v2 (available in Workflows)
// Scopes: environment-api:credentials:read, environment-api:metrics.ingest
import {
  credentialVaultClient,
  metricsClient,
  // Types for intellisense (optional)
  CredentialsDetailsTokenResponseElement,
} from '@dynatrace-sdk/client-classic-environment-v2';

export default async function () {
  console.log("ğŸš€ Cohesity Helios â†’ Dynatrace metrics (READ-ONLY)");

  // --- ğŸ” 1) Resolve token from Credential Vault (TOKEN type)
  //    Option A: use the Credential ID (recommended for reliability)
  //    Option B: if you donâ€™t know the ID, map a â€œcredentials.<name>â€ input in the step and fallback.
  let heliosApiKey = null;

  // ğŸ‘‰ Replace with your credential ID from the vault UI ("Copy ID")
  const CREDENTIAL_ID = 'CREDENTIALS_VAULT-xxxxxxxxxxxxxxxx'; // <-- put your real ID

  try {
    const tokenCred = /** @type {CredentialsDetailsTokenResponseElement} */ (
      await credentialVaultClient.getCredentialsDetails({ id: CREDENTIAL_ID })
    );
    if (tokenCred?.token) {
      heliosApiKey = tokenCred.token;
      console.log("âœ… Token retrieved from Credential Vault (by ID).");
    }
  } catch (e) {
    console.warn("âš ï¸ Vault lookup by ID failed or not configured. Will try step credential mappingâ€¦", e?.message || e);
  }

  // Fallback: if you mapped a token as a step credential input named â€œCohesity_API_Keyâ€
  if (!heliosApiKey && typeof credentials?.Cohesity_API_Key?.token === 'string') {
    heliosApiKey = credentials.Cohesity_API_Key.token;
    console.log("âœ… Token retrieved from step credentials (Cohesity_API_Key).");
  }

  if (!heliosApiKey) {
    throw new Error("âŒ No Helios API token available. Configure Credential Vault (Token) or step credential mapping.");
  }

  // --- 2) Call Cohesity Helios (READ-ONLY)
  const baseUrl = "https://helios.cohesity.com";
  const oneTiB  = 1099511627776;
  const headers = { accept: "application/json", apiKey: heliosApiKey };

  // Inventory
  const listUrl  = `${baseUrl}/v2/mcm/cluster-mgmt/info`;
  const listResp = await fetch(listUrl, { method: "GET", headers });
  if (listResp.status !== 200) throw new Error(`Cluster list failed (HTTP ${listResp.status})`);
  const data     = await listResp.json();
  const clusters = data?.cohesityClusters || [];
  if (clusters.length === 0) {
    console.log("âš ï¸ No clusters returned from Helios.");
    return { clusters: [] };
  }

  const results = [];
  const lines   = []; // metrics ingestion lines

  for (const { clusterName, clusterId } of clusters) {
    const h = { ...headers, accessClusterId: String(clusterId) };

    // Build entityId for timeSeriesStats
    const safeName = clusterName.replace(/\s+/g, '');
    const entityId = `${safeName}+(ID+${clusterId})`;

    // Garbage bytes (latest point)
    const tsUrl =
      `${baseUrl}/irisservices/api/v1/public/statistics/timeSeriesStats` +
      `?schemaName=ApolloV2ClusterStats` +
      `&metricName=EstimatedGarbageBytes` +
      `&startTimeMsecs=2` +
      `&entityId=${encodeURIComponent(entityId)}` +
      `&rollupFunction=latest` +
      `&rollupIntervalSecs=30` +
      `&metricUnitType=0` +
      `&range=day`;

    const tsResp = await fetch(tsUrl, { method: "GET", headers: h });
    if (tsResp.status !== 200) {
      console.log(`âš ï¸ Garbage stats GET failed for ${clusterName} (HTTP ${tsResp.status})`);
      continue;
    }
    const tsJson = await tsResp.json();
    const latest = Array.isArray(tsJson?.dataPointVec)
      ? tsJson.dataPointVec[tsJson.dataPointVec.length - 1]
      : undefined;
    const garbageBytes = latest?.data?.int64Value ?? 0;
    const garbageGB    = +(garbageBytes / (1024 ** 3)).toFixed(2);
    const garbageTB    = +(garbageBytes / (1024 ** 4)).toFixed(3);

    // Capacity
    const capUrl  = `${baseUrl}/irisservices/api/v1/public/stats/storage`;
    const capResp = await fetch(capUrl, { method: "GET", headers: h });
    if (capResp.status !== 200) {
      console.log(`âš ï¸ Capacity stats GET failed for ${clusterName} (HTTP ${capResp.status})`);
      continue;
    }
    const s = await capResp.json();
    const totalTiB = +(s.totalCapacityBytes   / oneTiB).toFixed(2);
    const usedTiB  = +(s.localUsageBytes      / oneTiB).toFixed(2);
    const availTiB = +(s.localAvailableBytes  / oneTiB).toFixed(2);
    const consumed = +((s.localUsageBytes / s.totalCapacityBytes) * 100).toFixed(2);

    results.push({
      clusterName, clusterId, totalTiB, usedTiB, availTiB, consumedPercent: consumed, garbageGB, garbageTB
    });

    // --- 3) Build Metrics v2 ingestion lines (one line per metric)
    // NOTE: Dimensions are labels you can split on in Data explorer (dashboard table).
    const dims = `clusterName="${clusterName.replace(/"/g, '\\"')}",clusterId="${clusterId}"`;
    lines.push(
      `cohesity.capacity.total.tib,${dims} ${totalTiB}`,
      `cohesity.capacity.used.tib,${dims} ${usedTiB}`,
      `cohesity.capacity.avail.tib,${dims} ${availTiB}`,
      `cohesity.capacity.consumed.percent,${dims} ${consumed}`,
      `cohesity.garbage.gb,${dims} ${garbageGB}`,
      `cohesity.garbage.tb,${dims} ${garbageTB}`,
    );

    console.log(`âœ… ${clusterName}: ${consumed}% used (${usedTiB}/${totalTiB} TiB) | Garbage ${garbageGB} GB`);
  }

  // --- 4) Ingest metrics into Dynatrace
  if (lines.length > 0) {
    const body = lines.join('\n');
    await metricsClient.ingest({ body }); // Metrics API v2 ingestion
    console.log(`ğŸ“¥ Ingested ${lines.length} metric lines to Dynatrace.`);
  }

  // Return useful payload (also visible in workflow run result)
  return { clusters: results };
}
