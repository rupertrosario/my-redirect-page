// Dynatrace Workflow JavaScript â€“ Cohesity Helios Read-Only + Metrics ingest
// Requires workflow permission: environment-api:metrics:ingest
import { metricsClient } from '@dynatrace-sdk/client-classic-environment-v2';

export default async function () {
  console.log("ğŸš€ Cohesity Helios â€“ Read-Only (GET to Cohesity) + Dynatrace metrics ingest");

  // ğŸ”‘ Inline key for now (move to Credential Vault later)
  const apiKey  = "PASTE_YOUR_API_KEY_HERE";
  const baseUrl = "https://helios.cohesity.com";
  const oneTiB  = 1099511627776;
  const headers = { accept: "application/json", apiKey };

  // Helper: try a GET and return {ok, json?, text?, status}
  async function tryGet(url, h) {
    const resp = await fetch(url, { method: "GET", headers: h });
    if (resp.status === 200) {
      return { ok: true, status: 200, json: await resp.json() };
    }
    const text = await resp.text().catch(() => "");
    return { ok: false, status: resp.status, text };
  }

  // Helper: robust garbage fetch with multiple entityId variants
  async function getGarbageLatest(clusterName, clusterId, h) {
    const safeName = clusterName.replace(/\s+/g, '');
    // 3 patterns commonly seen across Helios builds
    const variants = [
      `${safeName}+(ID+${clusterId})`,   // your original convention
      `${safeName}(ID ${clusterId})`,    // no pluses, space before (ID
      `${clusterName}(ID ${clusterId})`, // full spaced name
    ];

    const endMs   = Date.now();
    const startMs = endMs - 24 * 60 * 60 * 1000; // last 24h window

    for (const v of variants) {
      const entityIdEnc = encodeURIComponent(v);
      const url =
        `${baseUrl}/irisservices/api/v1/public/statistics/timeSeriesStats` +
        `?schemaName=${encodeURIComponent('ApolloV2ClusterStats')}` +
        `&metricName=${encodeURIComponent('EstimatedGarbageBytes')}` +
        `&entityId=${entityIdEnc}` +
        `&startTimeMsecs=${startMs}` +
        `&endTimeMsecs=${endMs}` +
        `&rollupFunction=latest`;

      console.log(`ğŸ”— Garbage GET â†’ ${url}`);
      const r = await tryGet(url, h);
      if (r.ok && Array.isArray(r.json?.dataPointVec)) {
        const vec = r.json.dataPointVec;
        const latest = vec.length ? vec[vec.length - 1] : undefined;
        const bytes = latest?.data?.int64Value ?? 0;
        return { bytes, variant: v };
      } else {
        console.log(`âš ï¸ Garbage GET failed (variant='${v}', HTTP ${r.status}) â†’ ${r.text || 'no body'}`);
      }
    }
    // All variants failed
    return { bytes: 0, variant: null, failed: true };
  }

  // 1) Inventory
  const listUrl  = `${baseUrl}/v2/mcm/cluster-mgmt/info`;
  const listResp = await fetch(listUrl, { method: "GET", headers });
  if (listResp.status !== 200) throw new Error(`âŒ Cluster list failed (HTTP ${listResp.status})`);
  const data     = await listResp.json();
  const clusters = data?.cohesityClusters || [];
  if (clusters.length === 0) {
    console.log("âš ï¸ No clusters returned.");
    return { clusters: [] };
  }

  const results = [];
  const lines   = []; // Dynatrace Metrics v2 payload lines

  // 2) Per-cluster GETs (garbage + capacity)
  for (const { clusterName, clusterId } of clusters) {
    const h = { ...headers, accessClusterId: String(clusterId) };
    console.log(`ğŸ“Š Reading ${clusterName} (ID ${clusterId})`);

    // Garbage (robust)
    const g = await getGarbageLatest(clusterName, clusterId, h);
    const garbageBytes = g.bytes;
    const garbageGB    = +(garbageBytes / (1024 ** 3)).toFixed(2);
    const garbageTB    = +(garbageBytes / (1024 ** 4)).toFixed(3);
    if (g.failed) {
      console.log(`âŒ Garbage not available for ${clusterName}; continuing with capacity only.`);
    } else {
      console.log(`ğŸ§¹ Garbage OK for ${clusterName} via entityId variant '${g.variant}' â†’ ${garbageGB} GB`);
    }

    // Capacity
    const capUrl  = `${baseUrl}/irisservices/api/v1/public/stats/storage`;
    const capTry  = await tryGet(capUrl, h);
    if (!capTry.ok) {
      console.log(`âš ï¸ Capacity GET failed for ${clusterName} (HTTP ${capTry.status}) â†’ ${capTry.text || 'no body'}`);
      continue;
    }
    const s = capTry.json;
    const totalTiB = +(s.totalCapacityBytes  / oneTiB).toFixed(2);
    const usedTiB  = +(s.localUsageBytes     / oneTiB).toFixed(2);
    const availTiB = +(s.localAvailableBytes / oneTiB).toFixed(2);
    const consumed = +((s.localUsageBytes / s.totalCapacityBytes) * 100).toFixed(2);

    results.push({
      clusterName, clusterId,
      totalTiB, usedTiB, availTiB,
      consumedPercent: consumed,
      garbageGB, garbageTB
    });

    console.log(`âœ… ${clusterName}: ${consumed}% used (${usedTiB}/${totalTiB} TiB) | Garbage ${garbageGB} GB (${garbageTB} TB)`);

    // Build metric lines
    const dims = `clusterName="${clusterName.replace(/"/g, '\\"')}",clusterId="${clusterId}"`;
    lines.push(
      `cohesity.capacity.total.tib,${dims} ${totalTiB}`,
      `cohesity.capacity.used.tib,${dims} ${usedTiB}`,
      `cohesity.capacity.avail.tib,${dims} ${availTiB}`,
      `cohesity.capacity.consumed.percent,${dims} ${consumed}`,
      `cohesity.garbage.gb,${dims} ${garbageGB}`,
      `cohesity.garbage.tb,${dims} ${garbageTB}`
    );
  }

  // 3) Ingest metrics to Dynatrace (POST to Dynatrace only)
  if (lines.length > 0) {
    console.log(`ğŸ“¡ Ingesting ${lines.length} lines to Dynatrace...`);
    await metricsClient.ingest({ body: lines.join('\n') });
    console.log("âœ… Metrics successfully ingested to Dynatrace");
  } else {
    console.log("â„¹ï¸ No metric lines to ingest.");
  }

  console.log("ğŸ“„ Final summary (read-only):");
  console.log(JSON.stringify(results, null, 2));
  return { clusters: results };
}
